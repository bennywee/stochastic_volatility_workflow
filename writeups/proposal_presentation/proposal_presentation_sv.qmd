---
title: "Comparison of MCMC algorithms in Stochastic Volatility Models"
format: 
    beamer:
        incremental: true
        header-includes: |
            \setbeamertemplate{itemize items}[circle]
author: "By Benjamin Wee"
institute: "Supervised by Catherine Forbes and Lauren Kennedy"
---

## Background
- Stochastic volatility models the variance of a financial instrument as a random variable

- Variety of Bayesian estimation strategies using classic Markov Chain Monte Carlo (MCMC) algorithms such as Gibbs and Metropolis Hastings

- Since then, more advanced algorithms such as Hamiltonian Monte Carlo has enabled the estimation of richer and more complicated models

- As the developments of these tools enable the estimation of more complicated models so do the risk of mistakes and the need to validate the output of our algorithms. How do we ensure the validity of our inferences across different estimation strategies?

<!-- What is the fundamental difference between convergence diagnostics, bayes factors with SBC? Check the fit of the model?-->

## Research Goal

Validate the computational methods used to estimate Bayesian stochastic volatility (SV) models

. . .

- 3 key components
    + Kim, Sherphard and Chib (1998) SV model
    + Hamiltonian Monte Carlo
    + Simulation Based Calibration to validate MCMC computation

## Stochastic Volatility (SV) model
KSC (1998) estimate a univariate discrete time SV model which models the variance as a latent stochastic process.

. . .

$$
\begin{aligned}
y_t =& \space \beta e^{h_t/2} \epsilon_t \\
h_{t+1} =& \space \mu +\phi(h_t - \mu) + \sigma_{\eta} \eta_t  \\
h_1 \sim& \space normal\left(\mu, \frac{\sigma_{\eta}^2}{1-\phi^2}\right) \\
\epsilon_t \sim &N(0,1) \space\space\space \eta_t \sim N(0,1)
\end{aligned}
$$

. . .

<!-- :::{.nonincremental} -->
- $y_t$ is mean corrected returns for equally spaced intervals $t$

- $\beta = exp(\mu / 2)$ constant scaling factor (set to 1)

- $h_t$ is log volatility where $h_1$ is a draw from a stationary distribution and the state equation $h_{t+1}$ is a stationary process governed by the autoregressive parameter $\phi$ where $|\phi|<1$.

- $\mu$ is the "average" log volatility

<!-- ::: -->

#  Estimation strategy

## Kim Sherphard Chib (1998)
:::{.nonincremental}
- Estimation of states using a Kalman filter, however, this requires the model to be linear and Gaussian. 

. . .

- Log and square both sides to linearise the model

. . .

$$
\begin{aligned}
y_t^{*} &= log(y_t^2) \\ 
&= log((\epsilon_t exp(h_t/2))^2) \\
&=  log(exp(h_t)) + log(\epsilon_t^2) \\
&= h_t + log(\epsilon_t^2)  \\
&= h_t + z_t \\
\end{aligned}
$$

Where $z_t = log(\epsilon_t^2)$ follows a log chi-squared distribution with mean -1.2704 and variance 4.93.

:::

## Kim Sherphard Chib (1998) Estimation strategy
Model is now linear but not Gaussian. KSC use a mixture of Gaussians to **approximate** the first 4 moments of the log chi squared distribution through moment matching. This is defined by:

$$
\begin{aligned}
f(z_t) = \sum_{i=1}^{K} q_if_N(z_i|m_i-1.2704, \nu_i^2)
\end{aligned}
$$

K is the mixture of 7 normal densities $f_N$, component probabilities $q_i$, mean $m_i-1.2704$ and variance $\nu_i^2$.

. . .

The static parameters $\mu$ and $\sigma^2$ are sampled directly from their conjugate posterior distributions where as $\phi$ is sampled via a metropolis hastings accept/reject procedure.

## Hamiltonian Monte Carlo (HMC)
- Key innovations: 

    + Uses the gradients of the target posterior distribution to generate an efficient path for the sampler to explore. 

    + Runs physics simulation - imagine the parameter is a marble rolling in random directions inside a bowl

    + Allows for direct sampling of the specified stochastic volatility model
    
- The Stan programming language's implementation of Hamiltonian Monte Carlo, the No-U-Turn Sampler (Hoffman & Gelman 2014), will be compared with KSC's strategy.

# Simulation Based Calibration (SBC)

## Simulation Based Calibration (SBC)
Let $\theta$ be a parameter and $y$ represent the dataset. Start with draw a sample from the prior distribution:
$$
\begin{aligned}
\theta^{sim} \sim \pi(\theta)
\end{aligned}
$$

. . .

Generate a dataset given by the prior draws.

$$
\begin{aligned}
y^{sim} \sim \pi (y|\theta^{sim})
\end{aligned}
$$

. . .

Then take draws from the posterior distribution generated by a MCMC algorithm or estimation strategy (Hamiltonian Monte Carlo or Gaussian approximation in our case).

$$
\begin{aligned}
\{\theta_1,\dots , \theta_{L}\} \sim \pi (\theta | y^{sim})
\end{aligned}
$$


## Simulation Based Calibration (SBC)
The rank statistic for a given parameter and simulation follows a discrete uniform distribution (proven in Talts et al. (2018)).

$$
\begin{aligned}
r = rank(\{\theta_1,\dots , \theta_{L}\}, \theta^{sim}) = \sum_{l=1}^{L}1[\theta_{l} < \theta^{sim}]
\end{aligned}
$$

Therefore, any deviation of the posterior samples from the prior distribution suggests an error - either in computation, code or overall analysis. 

If Bayesian computation is well calibrated, then the posterior (credible) intervals will have sufficient coverage. That is, for any percentage interval selected (for example 90%) then 90\% of these constructed intervals will contain $\theta^{sim}$.

<!-- Algorithm, computation, model strategy on average fails to estimate the parameters of a known data generating process. Whether or not the model is fit for a particular use case is not answered here. It's whether the model can capture the _assumed_ structure of the proposed DGP (we can't tell if this DGP is "correct" in the real world) -->

# Results

## HMC Results (1000 iterations)

![](../../simulation_output/sbc_ncp_ksc_priors_0.999_adapt_delta_premade_datasets_r7_1000_iterations/static_state_hist.png){fig-align="center" height=90%}

## HMC Results (5000 iterations)

![](../../simulation_output/sbc_ncp_ksc_priors_0.999_adapt_delta_premade_datasets_r6_5000_iterations/static_state_hist.png){fig-align="center" height=90%}

## Gaussian mixture Results (1000 iterations)

![](../../simulation_output/sbc_cp_ksc_model_cp_dgf_r1/static_state_hist.png){fig-align="center" height=90%}

## Next steps
:::{.nonincremental}
- Increasing number of posterior draws for KSC model
    + MCMC may not have converged onto target distribution

- Different model parameterisation
    + Performance of a sampler may be sensititive to the shape of the posterior density

- KSC's correction using importance sampling weights
    + Reweight samples from Gaussian mixture so that the new draws come from the correct distribution

:::

# Appendix

## Simulation Based Calibration (SBC)
A key result from this procedure is that the posterior sample $\{\theta_1,\dots , \theta_{L}\}$ will share the same distribution as the prior samples.

$$
\begin{aligned}
\pi(\theta) &= \int \pi(\theta|y^{sim}) \pi(y^{sim}|\theta^{sim}) \pi(\theta^{sim})dy^{sim} d\theta^{sim}  \\
&= \int \pi(\theta|y^{sim}) \pi(y^{sim},\theta^{sim}) dy^{sim} d\theta^{sim}
\end{aligned}
$$

That is, the posterior averaged over the joint distribution follows the same distribution as the prior. The rank statistic for a given parameter and simulation follows a discrete uniform distribution (proven in Talts et al. (2018)).
