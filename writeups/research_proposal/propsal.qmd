---
title: "Comparison of MCMC algorithms in Stochastic Volatility Models"
author: 
    - "By Benjamin Wee (32921020)" 
    - "Supervised by Catherine Forbes and Lauren Kennedy"
# abstract: "The objective of this research is to validate and compare the computational methods used to estimate Bayesian stochastic volatility models. Specifically, Simulation Based Calibration will be used to identify biases and errors arising from the results of Markov Chain Monte Carlo (MCMC) algorithms. The source of any miscalibration include, but are not limited to, estimation strategies, choice of sampler, model specifications and coding mistakes. This study will compare the estimation strategies detailed in the stochastic volatility literature with Hamiltonian Monte Carlo for estimating these class of models. Results and diagnostics from these simulations will help identify strengths and limitations that arise from these approaches."
format:
  pdf:
    fig-pos: H
    include-in-header:
        text: |
          \usepackage{lipsum}
          \usepackage{setspace}
          \onehalfspacing
          \linespread{1.5}
fontsize: 12pt
geometry: margin=1in
mathspec: true
---

<!-- # Background and Motivation
Maybe focus on the MCMC as opposed to SV upfront.

## SV
Why model volatility. Quantifying risks, tail probabilities, worst case scenarios. These are all inputs in the pricing of assets and derivatives. (pg92 FE slides)

SV models is one way to model volatility. Unlike the classic Black Scholes option pricing formula, it assumes that the underlying variance of an asset's return is not constant. That is, the variance of the underlying asset return is treated as a latent random variable. This deals with some of the empirical short comings of the BS model such as the volatility smile and skew in the realised variance in financial assets. 

SV models are typically expressed as non linear Gaussian state space models. This can make it difficult to estimate using classical methods. The likelihood is unavailable in closed form and there are at least as many variables as data points. There are however, a variety of Frequentist and Bayesian strategies for estimating SV models. Frequentist approaches include quasi likelihood estimation and GMM which rely on asymptotic sampling distributions. Bayesian approaches rely on computational Markov Chain Monte Carlo techniques to sample from the target joint posterior of these high dimensional state space models. 

This research will focus on Bayesian estimation strategies for Stochastic Volatility models. Particular attention will be given to the computational tools and approaches used to sample from high dimensional posterior distributions. Early approaches for estimating these models relied on classic Gibbs and Metropolis Hastings algorithms to apply the MCMC routines. Since then, there have been many developments in the availability of new kinds of MCMC samplers. 

Hamiltonian Monte Carlo is a . It has been popularised through its implementation in a variety of open source programming languages. It presents a new way to sample from increasingly complicated generative models . 

However, as the developments of these tools enable the estimation of more complicated models (with relative ease and accessibility through the development of open source software), so do the risk of mistakes and the need for procedures diagnose problems or mistakes when implementing these methods. How do we know that these algorithms are doing what we expect them to be doing, and how can we effectively differentiate the strengths and weaknesses of different tools.

How do we validate the computation and implementation of our sampling strategies and algorithms in increasingly complex models? And how do these form part of the computational modelling workflow?    -->

<!-- ## HMC
- There have been many developemnts over the past few decades on estimating Bayesian models through Markov Chain Monte Carlo methods. 

The original BUGs software implemented Gibbs and Metropolis Hastings MCMC algorithms for estimating this model. 

In particular, the availability of Hamiltonian Monte Carlo, a variant of the Metropolis Hastings algorithm, represents a recent advancement MCMC. 

- The development of HMC is another advancement in estimating complicated, high dimensional models. 
- Development of diagnostics for different types of HMC and tools for evaluating the convergence and efficiency of the MCMC sampler.  

- SV models are a primary candidate for using MCMC methods? Difficult to 

## SBC -->



<!-- and provide tools for evaluating other types models and algorithms.  -->

<!-- The objective of this research is to evaluate the performance of MCMC algorithms for estimating SV models through a simulation study. Simulations are useful since there is control over the data generating process. This will help us understand the behaviour of MCMC and evaluate its performance against known parameters. Particular attention will be given to the calibration of the MCMC algorithms in the stochastic volatility context. Further diagnostics to evaluate performance will be explored to determine the efficiency of the MCMC sampler. 

The first step is to understand what "performance" of MCMC algorithms means and what exactly we are measuring. At a high level, the objective of MCMC is to sample from the target posterior distribution and to provide reliable inference.  Convergence to the target posterior can be measured through efficiency measures such as rhat and effective sample size. 

- Explcitly outline what is compared. KSC and HMC algorithms and estimation strategies.  -->

<!-- 
Frequentist methods 

- Variety of estimation strategies 

- There are a variety of ways of estimating this model using a Bayesian frameworks. 

Over the past few decades there have been many developments in computing hardware -->
<!-- 
RESEARCH GOAL: To compare the performance of different MCMC algorithms and estimation strategies when fitting stochastic volatility models. The study will use a discrete formulation is described  -->

<!-- The use of simulation and sampling are used as part of model diagnostics and evaluation. -->

## 1. Research Goal

The objective of this research is to compare the computational methods used to estimate Bayesian stochastic volatility models. A simulation study will compare the estimation strategies detailed in the stochastic volatility literature with Hamiltonian Monte Carlo and their ability to sample from the model's posterior distribution. Specifically, Simulation Based Calibration (SBC) is used to check whether these sampling strategies are returning efficient and well calibrated posterior estimates. Key metrics of interest are the effective sample size to check the efficiency of the algorithm and tests of uniformity to assess the calibration of the posteriors. This will determine which algorithm is better at estimating stochastic volatility models based on the efficiency and accuracy of the sampling strategy.


<!-- Stochastic volatility models are used to explicitly model the variance of returns in financial instruments and can be estimated using frequentist or Bayesian frameworks.  -->

<!-- 
The objective of this research is to validate the computational methods used to estimate Bayesian stochastic volatility models. This study will assess the estimation strategies detailed in the stochastic volatility literature with Hamiltonian Monte Carlo for estimating these class of models. A simulation study will compare the ability of these methods to sample from the model's posterior distribution. Specifically, Simulation Based Calibration (SBC) is used to check whether these sampling strategies are returning efficient and well calibrated posterior estimates. Key metrics to check these features are the effective sample size to check efficiency of the algorithm and tests of uniformity to determine calibration of the posteriors. This will determine which algorithm is better at estimating stochastic volatility models based on the efficiency and accuracy of the sampling strategy. -->



<!-- Simulation Based Calibration will be used to identify biases and errors arising from the results of Markov Chain Monte Carlo (MCMC) algorithms. The source of any miscalibration include, but are not limited to, estimation strategies, choice of sampler, model specifications and coding mistakes. This study will compare the estimation strategies detailed in the stochastic volatility literature with Hamiltonian Monte Carlo for estimating these class of models. Results and diagnostics from these simulations will help identify strengths and limitations that arise from these approaches. -->

<!-- The objective of this research is to validate and compare the computational methods used to estimate Bayesian stochastic volatility models. Specifically, Simulation Based Calibration will be used to identify biases and errors arising from the results of Markov Chain Monte Carlo (MCMC) algorithms. The source of any miscalibration include, but are not limited to, estimation strategies, choice of sampler, model specifications and coding mistakes. This study will compare the estimation strategies detailed in the stochastic volatility literature with Hamiltonian Monte Carlo for estimating these class of models. Results and diagnostics from these simulations will help identify strengths and limitations that arise from these approaches. -->

<!-- Specifically, they propose a method of sampling by using an offset mixture normal approximation with a reweighting procedure to sample from the posterior distribution. By linearing the model and using a mixture of Gaussians, they were able to apply a Kalman Filter to estimate the posterior density over the latent volatilities and static parameters. -->

<!-- The univariate stochastic volatility model described in their paper outlines the state space representation of the the model which is described below.
 -->
# 2. Background and Literature Review

## 2.1 Stochastic Volatility
Stochastic volatility models are used in financial econometrics to model the variance or volatility of returns in a financial instrument. The return of a financial asset often exhibits patterns in the variance which can be modeled to improve prediction and estimates of risk or tail events. Unlike other volatility models such as ARCH or GARCH, stochastic volatility models treat the variance as a random variable. Furthermore, these models have a state space representation since the variance is expressed as a latent stochastic process. State space models can be difficult to estimate since there is a latent state for every data observation in the time series, which means there are often more parameters than data points. These models can be estimated using frequent frameworks but this research will focus on Bayesian estimation strategies.  

Kim, Shephard and Chib (1998) estimate a discrete time, univariate stochastic volatility model using Bayesian methods which is outlined below. $y_t$ is the mean corrected returns of some asset for equally spaced intervals t. $\beta$ is a constant scaling factor which is also defined as $exp(\mu / 2)$ representing instantaneous volatility. $h_t$ is log volatility, where $h_1$ is a draw from a stationary distribution and the state equation $h_{t+1}$ follows a stationary process governed by the autoregressive parameter $\phi$ such that $|\phi|<1$. This autoregressive parameter represents the persistence or "stickiness" of log volatility and the dispersion parameter $\sigma_{\eta}$ is the constant variance of the states. $\epsilon_t$ and $\eta_t$ are standard normal white noise shocks and are uncorrelated with each other. 

$$
\begin{aligned}
y_t =& \space \beta exp(h_t/2) \epsilon_t \\
h_{t+1} =& \space \mu +\phi(h_t - \mu) + \sigma_{\eta} \eta_t  \\
h_1 \sim& \space normal\left(\mu, \frac{\sigma_{\eta}^2}{1-\phi^2}\right) \\
\end{aligned}
$$


$$
\begin{aligned}
\epsilon_t \sim& \space normal(0,1) \\
\delta_t \sim& \space normal(0,1)
\end{aligned}
$$

Setting $\beta=1$, the model can be expressed more succinctly as:

$$
\begin{aligned}
y_t \sim& \space normal(0, exp(h_t/2)) \\ 
h_1 \sim& \space normal \left(\mu, \frac{\sigma_{\eta}^2}{1-\phi^2}\right) \\
h_{t+1} \sim& \space normal(\mu +\phi(h_t - \mu) , \sigma_{\eta}^2), \space\space t\neq 1\\ 
\end{aligned}
$$

Priors for the static parameters are defined below with conjugate priors on $\mu$ and $\sigma^2$:

$$
\begin{aligned}
\mu \sim& \space normal(0, 10^2) \\
\sigma_{\eta}^2 \sim& \space IG(5/2, (0.01\times 5) / 2) \\
\phi^{\ast} \sim& \space beta(20, 1.5) \\
\phi &=  2\phi^{\ast} - 1
\end{aligned}
$$

The prior on $\phi$ is a "stretched" beta distribution. This is a beta distribution (as defined on the parameter $\phi^*$) which has been transformed to have support (-1, 1).

### Estimation strategy
Kim, Shephard and Chib (KSC) sample the posteriors of the stochastic volatility model using a mix of conjugate posterior distributions, Metropolis Hastings and the Kalman Filter and smoother[^1] (de Jong and Shephard, 1995).

[^1]: In this research the exact software to apply the simulation smoother is unavailable, so a more recent simulation smoother is used which is based on the software written by the same author. 

The standard Kalman Filter and smoother is used to compute the posterior distribution over the latent states. This requires the state and measurement equations to be linear and conditionally Gaussian. Since the relationship between $y_t$ and $h_t$ in the measurement equation is not linear, a transformation is applied by squaring and taking the log of $y_t$.

$$
\begin{aligned}
y_t^{*} &= log(y_t^2) \\ 
&= log((\epsilon_t exp(h_t/2))^2) \\
&=  log(exp(h_t)) + log(\epsilon_t^2) \\
&= h_t + log(\epsilon_t^2)  \\
&= h_t + z_t \\
\end{aligned}
$$

Where $z_t = log(\epsilon_t^2)$ follows a log chi-squared distribution with mean -1.2704 and variance 4.93. The relationship between $y_t$ and $h_t$ is now linear; however, the error is not Gaussian. Since it is not simple to sample from this parameterisation of the model, KSC use a mixture of Gaussians to **approximate** the first 4 moments of the log chi squared distribution. This is defined by:

$$
\begin{aligned}
f(z_t) = \sum_{i=1}^{K} q_if_N(z_i|m_i-1.2704, \nu_i^2)
\end{aligned}
$$

Where K is the mixture of normal densities $f_N$, component probabilities $q_i$, mean $m_i-1.2704$ and variance $\nu_i^2$. These parameters were selected using moment matching where they found 7 normal densities with varying mean and variance parameters best approximated the log chi squared moments. These parameters and weights can be found in Appendix A.

The model can be sampled via the Kalman Filter and simulation smoother since the model is now linear and conditionally gaussian. The static parameters $\mu$ and $\sigma^2$ are sampled directly from their conjugate posterior distributions whereas $\phi$ is sampled via a Metropolis Hastings accept/reject procedure. The details can be around in Appendix B. 

## 2.2 Hamiltoninan Monte Carlo
Since the paper was written, new MCMC algorithms have been developed and enabled the estimation of richer and more complicated models. Specifically, Hamiltonian Monte Carlo is a MCMC algorithm which has become widely available for efficiently sampling from sophisticated models. Hamiltonian Monte Carlo, originally called Hybrid Monte Carlo, was developed in the physics literature (Duane et al. 1987) before being applied in the statistics literature by Radford Neal through his works in Bayesian Neural Networks (Neal, 1995) and statistical computing (Neal 2011). The algorithm has since become widely available through open source development projects such as Stan (Stan Development Team, 2023) and PyMC (2023).

The key innovation of Hamiltonian Monte Carlo is using the gradients of the target posterior distribution to generate an efficient path for the sampler to explore. Unlike Random Walk Metropolis Hastings, it takes advantage of the geometry of the posterior to determine its next proposal step. A comprehensive explanation of the sampler is beyond the scope of this research and can be found in the above references. 

The Stan programming language's implementation of Hamiltonian Monte Carlo will be used for this study. Stan's default algorithm, the No-U-Turn Sampler (Hoffman & Gelman 2014), allows for direct sampling of the specified stochastic volatility model. Hamiltonian Monte Carlo allows for sampling of the generative model and can flexibly handle complicated likelihood functions. This approach will also use the same priors as specified in the Gaussian mixture approximation.

## 2.3 Research contribution
The goal of this research is to determine which algorithm is better at estimating the discrete time stochastic volatility model (conditional on the same priors). My main contribution is to design a simulation study that compares these algorithms and determines which sampling strategy is better based on the calibration of posterior estimates and the efficiency of the MCMC sampler.


<!-- New developments in MCMC algorithms and improved computing resources have enabled estimation of richer and more complicated models. However, as the development of tools enables us to fit more complicated models, so does the need to validate the output of these tools. Cook, Gelman and Rubin (2006) introduce simulation techniques to evaluate the "correctness" of the software used to sample Bayesian models. Their contribution identified that cumulative density quantiles from the posterior samples can be tested for uniformity. Talts et al (2018). build upon this work by developing Simulation Based Calibration to provide more robust validation of output from a MCMC sampler through the use of rank statistics. -->

 <!-- through the use of the CDF quantiles approximated from the posterior distribution. -->

<!-- , through open source programming languages such as Stan and PyMC, have become 

As new and complicated 


There have been many developments in MCMC algorithms since the introduction of classical methods such as Gibbs and Metropolis Hastings. 

Hamiltoninn Monte Carlo (algorithm introduced when, widely available since 2010...?) is a relatively new im.


- Since then, there have been many developments in MCMC algorithms. In particular, HMC provides a flexible alternative to fitting and sampling from complicated high dimensional Bayesian models.
- It's key innovation is the use of gradients - enabling the flexible specification of any likelihood function. 
- Constraints- can only sample from continuous 
- HMC also provides new diagnostics for evaluating the effectiveness of the sampling procedure and how well the sampler is targeting the joint dist. 

- How do we compare models? SBC. ESS in the tails, rhats. 

- Given this context, my research looks to compare the efficacy of KSCs proposed MCMC sampling strategy with Hamiltonina Monte Carlo (NUTs).  -->
 



# 3. Methodology

## 3.1 Design
Simulation Based Calibration (SBC) is a technique that checks the calibration of posterior estimates generated by MCMC algorithms. SBC is conducted by comparing the distribution of rank statistics to the discrete uniform distribution which arises when an algorithm is correctly calibrated. The procedure starts by taking draws from the prior distribution and creating datasets implied by each draw. Rank statistics are then calculated on the posterior samples conditional on the simulated data. 

To illustrate this procedure, let $\theta$ be a parameter and $y$ represent the dataset. Start with a single draw from the prior distribution:
$$
\begin{aligned}
\theta^{sim} \sim \pi(\theta)
\end{aligned}
$$

Generate a dataset given by the prior draw.

$$
\begin{aligned}
y^{sim} \sim \pi (y|\theta^{sim})
\end{aligned}
$$

Then take draws from the posterior distribution generated by a MCMC algorithm or estimation strategy (Hamiltonian Monte Carlo or KSC) conditional on this dataset.

$$
\begin{aligned}
\{\theta_1,\dots , \theta_{L}\} \sim \pi (\theta | y^{sim})
\end{aligned}
$$

A key result is that the posterior sample $\{\theta_1,\dots , \theta_{L}\}$ will share the same distribution as the prior samples $\theta^{sim}$. This is implied by the following expression:

$$
\begin{aligned}
\pi(\theta) &= \int \pi(\theta|y^{sim}) \pi(y^{sim}|\theta^{sim}) \pi(\theta^{sim})dy^{sim} d\theta^{sim} \\
&= \int \pi(\theta|y^{sim}) \pi(y^{sim},\theta^{sim}) dy^{sim} d\theta^{sim}
\end{aligned}
$$

That is, the posterior averaged over the joint distribution follows the same distribution as the prior. The procedure of generating posterior samples implicitly performs this integral since the expression on the right of the integral is proportional to the prior density. Therefore, any deviation of the posterior samples from the prior distribution suggests that the sampling methodology is not producing the correct posteriors.

<!-- n error - either in computation, code or overall analysis.  -->

<!-- The simulation if done correctly should produce samples from the prior distribution.  -->

If the posterior samples follows the prior distribution, the rank statistic for a given parameter follows a discrete uniform distribution[^2]. The rank statistic is defined as:

[^2]: Proof of this result in Talts et al (2018).

$$
\begin{aligned}
r = rank(\{\theta_1,\dots , \theta_{L}\}, \theta^{sim}) = \sum_{l=1}^{L}1[\theta_{l} < \theta^{sim}]
\end{aligned}
$$

This completes one iteration of SBC. To complete the algorithm, multiple iterations are run and the rank statistics are calculated for each parameter. The resulting rank statistics are compared to the discrete uniform distribution to determine if any problematic features exist.

If the computation is well calibrated and the rank statistics follow a discrete uniform distribution, then the posterior credible intervals have sufficient coverage. That is, one way to describe calibration is: for any percentage interval selected over the posterior samples (for example 90%) then there is a 90\% chance that $\theta^{sim}$ falls within this interval. Another way of saying this is a Bayesian analysis is well calibrated if a 90\% credible interval contains the true parameter in 90\% of the SBC iterations. 

## 3.2 Implementation
SBC for Hamiltonian Monte Carlo and the Gaussian approximation are performed with 1000 simulation iterations, 1000 observations in each dataset, and post warmup/burnin samples of 999 (which gives 1000 possible rank statistics). This algorithm is summarised below:

| **1) for sim in 1000 iterations:**
|   2) Draw from prior: $\theta^{sim}\sim\pi (\theta)$
|   3) Simulate dataset with 1000 observations: $y^{sim} \sim p(y|\theta^{sim})$
|   4) Draw 999 posterior samples (post warmup) $\{\theta_1,\dots , \theta_{L}\} \sim p(\theta | y^{sim})$
|   5) Compute rank statistics $r = rank(\{\theta_1,\dots , \theta_{L}\}, \theta^{sim})$

## 3.3 Metrics
The key metrics and diagnostics to compare the performance of these methods are the effective sample size (ESS), rank statistics, and chi-squared test statistics. 

ESS measures the efficiency of the MCMC sampler. It calculates the number of (effectively) independent draws from the posterior draws generated by a Markov chain. A poor ESS can arise from high autocorrelation in the Markov chain which leads to highly dependent samples. An efficient MCMC algorithm takes less resources (for example, time and number of draws) to get a representative sample of the target distribution. If a MCMC algorithm possesses higher ESS for the majority of its parameters (relative to another strategy), then we may conclude that this method is a more efficient sampler (conditional on the model). 

Rank statistics as described in the SBC section are used to evaluate the calibration of a posterior. Histograms will be used to evaluate the distribution of rank statistics. If a posterior is well calibrated then it is expected that the histogram is uniform.

A drawback of this approach is there are more parameters than data points in this model. An alternative to visually checking for uniformity of all the parameters is to calculate the chi squared statistics for the counts in each histogram bin. Let $b_j$ be the number of counts and $e_j$ the expected count in bin $j$. Then the chi squared statistic is given by:

$$
\begin{aligned}
\chi^2 = \sum_{j=1}^J \frac{(b_{j} - e_{j})^2}{e_j}
\end{aligned}
$$

Chi squared statistics can be used to test for uniformity and thus calibration of all the parameters in the model.

<!-- 
The aim of this research is to use Simulation Based Calibration (SBC) to validate the inference of posterior samples generated by different MCMC algorithms in the context of stochastic volatility models. This will help identify any bias in computation and inconsistencies in model implementation and estimation strategies. Comparison of the SBC results between different computational approaches may help identify any strengths or shortcomings as well as any errors in model specification.  -->

<!-- ## 3.1 Stochastic Volatility Model
The univariate stochastic volatility model described by Kim, Shephard and Chib (1998) models the variance as a random variable following some latent stochastic process. $y_t$ is the mean corrected returns of some asset for equally spaced intervals t. $\beta$ is a constant scaling factor which is also defined as $exp(\mu / 2)$ representing instantaneous volatility. $h_t$ is log volatility, where $h_1$ is a draw from a stationary distribution and the state equation $h_{t+1}$ follows a stationary process governed by the autoregressive parameter $\phi$ such that $|\phi|<1$. This autoregressive parameter represents the persistence or "stickiness" of log volatility and the dispersion parameter $\sigma_{\eta}$ is its variance. $\epsilon_t$ and $\eta_t$ are standard normal white noise shocks. 

$$
\begin{aligned}
y_t =& \space \beta exp(h_t/2) \epsilon_t \\
h_{t+1} =& \space \mu +\phi(h_t - \mu) + \sigma_{\eta} \eta_t  \\
h_1 \sim& \space normal\left(\mu, \frac{\sigma_{\eta}^2}{1-\phi^2}\right) \\
\end{aligned}
$$


$$
\begin{aligned}
\epsilon_t \sim& \space normal(0,1) \\
\delta_t \sim& \space normal(0,1)
\end{aligned}
$$

Setting $\beta=1$, the model can be expressed more succinctly as:

$$
\begin{aligned}
y_t \sim& \space normal(0, exp(h_t/2)) \\ 
h_1 \sim& \space normal \left(\mu, \frac{\sigma_{\eta}^2}{1-\phi^2}\right) \\
h_{t+1} \sim& \space normal(\mu +\phi(h_t - \mu) , \sigma_{\eta}^2), \space\space t\neq 1\\ 
\end{aligned}
$$

Priors for the static parameters are defined below with conjugate priors on $\mu$ and $\sigma^2$:

$$
\begin{aligned}
\mu \sim& \space normal(0, 10^2) \\
\sigma_{\eta}^2 \sim& \space IG(5/2, (0.01\times 5) / 2) \\
\phi^{\ast} \sim& \space beta(20, 1.5) \\
\phi &=  2\phi^{\ast} - 1
\end{aligned}
$$

The prior on $\phi$ is a "stretched" beta distribution. This is a beta distribution (as defined on the parameter $\phi^*$) which has been transformed to have support (-1, 1).

## 3.2 Estimation Strategy

### Gaussian Mixture Approximation
Kim, Shephard and Chib estimate the stochastic volatility model using a Kalman Filter and smoother[^1] (de Jong and Shephard, 1995) to compute the posterior distribution over the latent states. This requires the state space model to be linear and conditionally Gaussian. 

[^1]: In this research the exact software to apply the simulation smoother is unavailable, so a more recent simulation smoother is used which is based on the software written by the same author. 

Since the model is not linear, a transformation is applied by squaring and taking the log of $y_t$.

$$
\begin{aligned}
y_t^{*} &= log(y_t^2) \\ 
&= log((\epsilon_t exp(h_t/2))^2) \\
&=  log(exp(h_t)) + log(\epsilon_t^2) \\
&= h_t + log(\epsilon_t^2)  \\
&= h_t + z_t \\
\end{aligned}
$$

Where $z_t = log(\epsilon_t^2)$ follows a log chi-squared distribution with mean -1.2704 and variance 4.93. However, it is not simple to sample from this parameterisation of the model. Kim, Sherpherd and Chib use a mixture of Gaussians to **approximate** the first 4 moments of the log chi squared distribution. This is defined by:

$$
\begin{aligned}
f(z_t) = \sum_{i=1}^{K} q_if_N(z_i|m_i-1.2704, \nu_i^2)
\end{aligned}
$$

Where K is the mixture of normal densities $f_N$, component probabilities $q_i$, mean $m_i-1.2704$ and variance $\nu_i^2$. These parameters were selected using moment matching where they found 7 normal densities with varying mean and variance parameters best approximated the log chi squared moments. These parameters and weights can be found in Appendix A.

The model can be sampled via the simulation smoother since the model is now linear and conditionally gaussian. The static parameters $\mu$ and $\sigma^2$ are sampled directly from their conjugate posterior distributions where as $\phi$ is sampled via a metropolis hastings accept/reject procedure. The details can be be around in Appendix B. 

### Hamiltonian Monte Carlo (No-U-Turn Sampler)
The Stan programming language's implementation of Hamiltonian Monte Carlo will be used for this study. Stan's default algorithm, the No-U-Turn Sampler (Hoffman & Gelman 2014), allows for direct sampling of the specified stochastic volatility model. Hamiltonian Monte Carlo allows for sampling of the generative model and can flexibly handle complicated likelihood functions. This approach will use the same priors as specified in the Gaussian mixture approximation. However, Hamiltonian Monte Carlo does not sample directly from the analytical form of conjugate or conditionally conjugate distribution, so different priors can be chosen if necessary. 
 -->

<!-- SBC validates posterior samples and inferences generated by MCMC algorithms. It identifies inconsistencies and bias in computation and estimation of a generative model. This procedure  -->



<!-- ## Performance diagnostics

The goal of this simulation is to determine the "calibration" of MCMC when estimating SV models. 

ADEMP:
- Aims
- Data generating mechanism
    + Write out mathematical form of the model here. Discrete time. 
- Estimand /target of analysis (maybe after explaining SBC?)
- Methods
    + SBC. Evaluating "calibration" of MCMC. What does calibration mean?
- Performance measures
    + Rhats, ESS, histogram


- Convergence diagnostic onto target joint posterior distribution? rhats/ess. This assess "efficiency" of MCMC.
- Tail ESS calculates ESS in the tail quantiles. Such  -->

# 4. Preliminary Results
Figure 1 shows the distribution of rank statistics for Hamiltonian Monte Carlo, with the horizontal black line at 50 representing the discrete uniform distribution. The preliminary figures focus on the static parameters and arbitrarily chosen states. Phi and sigma_sqd look relatively uniform. However mu and h.995 (the 995th state parameter) have some lumpiness which may suggest a lack of calibration. 

![Distribution of parameter ranks for HMC algorithm (1000 iterations)](../../simulation_output/sbc_ncp_ksc_priors_0.999_adapt_delta_premade_datasets_r7_1000_iterations/static_state_hist.png){width=75%}

A drawback of SBC is that any deviation in uniformity from a calibrated analysis may be due to noisy estimates from small samples. Figure 2 shows more consistent uniform behaviour from all parameters after increasing the number of iterations from 1000 to 5000. This suggests that Hamiltonian Monte Carlo and the overall analysis is well calibrated.

![Distribution of parameter ranks for HMC algorithm (5000 iterations)](../../simulation_output/sbc_ncp_ksc_priors_0.999_adapt_delta_premade_datasets_r6_5000_iterations/static_state_hist.png){width=75%}

Figure 3 shows results for the Gaussian approximation. The distribution of the rank statistics deviates heavily from the expected discrete uniform distribution, with various peaks at each end of the histogram as well as peaks in the middle. A reason for this miscalibration may be due to the Gaussian mixture only approximating the log chi squared distribution. Hamiltonian Monte Carlo on the other hand, samples directly from the target model which more closely represents the data generating process.

This result may also be due to the relatively small number of posterior samples drawn from the model. The MCMC sampler may not have converged yet which may explain the deviations from uniformity. A follow up step is to compare the ESS of the two methods and to increase the length of the MCMC chain to ensure the ESS is approximately the same before comparing histograms.  

![Distribution of parameter ranks for Gaussian mixture model (1000 iterations)](../../simulation_output/sbc_cp_ksc_model_cp_dgf_r1/static_state_hist.png){width=75%}

<!-- An alternative to checking for uniformity of all the parameters is to calculate the chi squared statistics for the counts in each bin. Let $b_j$ be the number of counts and $e_j$ the expected count in bin $j$. Then the chi squared statistic is given by:

$$
\begin{aligned}
\chi^2 = \sum_{j=1}^J \frac{(b_{j} - e_{j})^2}{e_j}
\end{aligned}
$$

These chi squared statistics can be considered draws from a chi squared distribution with 19 degrees of freedom (since there are 20 bins). Visualising this should give a chi squared distribution (if performing a hypothesis test, this would be the sampling distribution under a null of uniformity). One caveat about this is the chi squared statistics calculated in this way may not be independent. That is, each iteration of SBC may be independent however, the calculation of the rank statistics for a given iteration may be dependent between some parameters (since each state parameter is a function of the previous state parameter).

Figure 4 and 5 are the chi squared statistic histograms results of Hamiltonian Monte Carlo and Gaussian approximation respectively. The vertical black line marks the 95th quantile which represents the critical value for hypothesis testing. The Hamiltonian Monte Carlo chi squared statistics look like they are sampled from the correct distribution, with 6.2\% of the samples greater than the 95\% critical value (doing this calculation for 5000 iterations leads to 4.8\% of samples in the critical area). Figure 5 shows the majority of chi squared statistics for Gaussian approximation within the critical area, suggesting the estimation strategy is not well calibrated. 

![Chi squared statistics for Hamiltonian Monte Carlo](../../simulation_output/sbc_ncp_ksc_priors_0.999_adapt_delta_premade_datasets_r7_1000_iterations/chi_sq_hist.png){width=70%}

![Chi squared statistics for Gaussian approximation](../../simulation_output/sbc_cp_ksc_model_cp_dgf_r1/chi_sq_hist.png){width=70%} -->

# 5. Conclusion and next steps
There are two key extensions to the simulation results worth exploring.

**1) Metropolis Hastings reweighting for KSC model**

Kim, Shephard and Chib apply importance sampling weights to correct for the approximation error of the Gaussian mixture model. According to the authors, the correction ensures that samples are from the exact posterior density. The next step is to perform this correction and evaluate the SBC results. I'd expect the Gaussian mixture approximation diagnostics to improve after this correction.

**2) Centered and non centered parameterisation**

The parameterisation of a model can affect the performance of a sampler. This can cause significant problems in getting unbiased MCMC samples for complex models. An example of this is Neal's funnel (Neal 2003) which arises in hierarchical models which causes performance issues in the Hamiltonian Monte Carlo sampler. Rewriting the model with non centered parameterisation significantly improves the performance of MCMC. Another consideration for this research is to consider both centered and non centered parameterisations of the stochastic volatility model to see if there are any improvements to the simulation diagnostics.

The models and parameterisations for this research are summarised in the below table:

![Model matrix](model_table.jpg)

## Plan
Week 7: Reflect and integrate feedback from presentation into plan for the rest of the semester

Week 8: Finish off any simulation or modelling not yet complete (listed in above matrix)

Week 9: Write up results and have a first draft ready for feedback

Week 10-11: Action any feedback, prepare for final submission and presentation

Week 12: Submit

{{< pagebreak >}}

# References

Abril-Pla O, Andreani V, Carroll C, Dong L, Fonnesbeck CJ, Kochurov M, Kumar R, Lao J, Luhmann CC, Martin OA, Osthege M, Vieira R, Wiecki T, Zinkov R. (2023) PyMC: a modern, and comprehensive probabilistic programming framework in Python.

Duane, Simon; Kennedy, Anthony D.; Pendleton, Brian J.; Roweth, Duncan (1987). "Hybrid Monte Carlo". Physics Letters B. 195 (2): 216–222. 

Hoffman, M. D., & Gelman, A. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. J. Mach. Learn. Res., 15(1), 1593-1623.

Kim, Sangjoon, Neil Shephard, and Siddhartha Chib. 1998. “Stochastic Volatility: Likelihood Inference and Comparison with ARCH Models.” Review of Economic Studies 65: 361–93. 

Neal, R.M. (1995) Bayesian Learning for Neural Networks. Ph.D. Thesis, Graduate Department of Computer Science, University of Toronto, Toronto. 

Neal, R. M. (2003). Slice Sampling. The Annals of Statistics, 31(3), 705–741. http://www.jstor.org/stable/3448413

Neal, R.M. (2011) MCMC Using Hamiltonian Dynamics. In Handbook of Markov Chain Mone Carlo, CRC Press, New York

Stan Development Team. 2023. Stan Modeling Language Users Guide and Reference Manual, 2.32. https://mc-stan.org

Talts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gelman, A. (2018). Validating Bayesian inference algorithms with simulation-based calibration. arXiv preprint arXiv:1804.06788.

{{< pagebreak >}}

# Appendix A: Mixture Gaussian weights

| $\omega$ | $Pr(\omega = i)$ | $m_i$ | $\nu^2_i$ |
|------|------|------|------|
| 1    | 0.00730    | -10.12999   | 5.79596 | 
| 2    | 0.10556    | -3.97281    | 2.61369 | 
| 3    | 0.00002    | -8.56686    | 5.17950 | 
| 4    | 0.04395    | 2.77786    | 0.16735 | 
| 5    | 0.34001    | 0.61942    | 0.64009 | 
| 6    | 0.24566    | 1.79518    | 0.34023 | 
| 7    | 0.25750    | -1.08819    | 1.26261 | 


{{< pagebreak >}}

# Appendix B: Sampling from mixture of Gaussians

## Conjugate posterior distributions

**Sampling** $\boldsymbol{\sigma_{\eta}^2}$

Inverse gamma conjugate posterior distribution:

$$
\sigma^2_{\eta} | y,h,\phi,\mu \sim IG \Bigl\{\frac{n+\sigma_r}{2}, \frac{0.05 + (h_1 - \mu)^2 (1 - \phi^2) + \sum_{t=1}^{n-1}((h_{t+1} - \mu) - \phi(h_t - \mu))^2}{2}\Bigr\}
$$

**Sampling** $\boldsymbol{\mu}$

Gaussian conjugate posterior distribution:

$$
\mu | h,\phi,\sigma^2_{\eta}  \sim N(\hat{\mu}, \sigma^2_{\mu})
$$

Where

$$
\begin{aligned}
\hat{\mu} &= \sigma^2_{\mu} \Bigl\{\frac{(1-\phi^2)}{\sigma_{\eta}^2}h_1 +\frac{(1-\phi^2)}{\sigma_{\eta}^2} \sum_{t=1}^{n-1} (h_{t+1} - \phi h_t)\Bigr\} \\
\sigma^2_{\mu} &= \sigma^2_{\eta} \{(n-1)(1-\phi)^2 + (1-\phi^2)\}^{-1}
\end{aligned}
$$

**Sampling** $\boldsymbol{\phi}$

Metropolis Hastings accept/reject procedure:

1) Generate proposal $\phi^\ast$ from $N(\hat{\phi}, V_{\phi})$ where $\hat{\phi} = \frac{\sum_{t=1}^{n-1} (h_{t+1} - \mu)(h_t - \mu)}{\sum_{t=1}^{n-1} (h_t - \mu)^2}$ and $V_{\phi} = \sigma^2_{\eta} \{\sum_{t=1}^{n-1} (h_t - \mu)^2\}^{-1}$

2) Accept proposal as $\phi^{(i)}$ with probability $e^{\{g(\phi^\ast) - g(\phi^{(i-1)}\}}$ such that $g(\phi) = log (\pi (\phi)) - \frac {(h_t - \mu)^2 (1-\phi^2)}{2 \sigma_{\eta}^2} + \frac{1}{2} log (1-\phi^2)$

**Sampling mixture density:**

Rewrite mixture density with respect to a indicator variable $s_t$

$$
\begin{aligned}
&z_t | s_t = i \sim N(m_i - 1.2704, \nu^2) \\
&Pr(s_t = i) = q_i
\end{aligned}
$$

Sample $s_t$ from probability mass function: 

$$
\begin{aligned}
Pr(s_t = i | y_t^{\ast}, h_t) \propto q_i f_N(y_t^{\ast} | h_t + m_t - 1.2704, \nu^2)
\end{aligned}
$$

**Sampling steps**

1. Set initial values $s$, $\phi$, $\sigma^2_{\eta}$ and $\mu$

2. Sample $h$ from $h|y^{\ast}, s, \phi, \sigma^2_{\eta}, \mu$

3. Sample s from $s|y^{\ast}, h$

4. Sample $\mu|y^{\ast}, s, \phi, \sigma^2_{\eta}, h$ according to conjugate posterior distribution

4. Sample $\sigma_{\eta}^2|y^{\ast}, s, \phi, \mu, h$ according to conjugate posterior distribution

4. Sample $\phi|y^{\ast}, s, \mu, \sigma^2_{\eta}, h$ using metropolis hastings 