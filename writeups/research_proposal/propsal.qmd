---
title: "Comparison of MCMC algorithms in Stochastic Volatility Models"
format:
  pdf:
    fig-pos: H
    include-in-header:
        text: |
          \usepackage{lipsum}
          \usepackage{setspace}
          \onehalfspacing
          \linespread{1.5}
fontsize: 12pt
geometry: margin=1in
---

<!-- # Background and Motivation
Maybe focus on the MCMC as opposed to SV upfront.

## SV
Why model volatility. Quantifying risks, tail probabilities, worst case scenarios. These are all inputs in the pricing of assets and derivatives. (pg92 FE slides)

SV models is one way to model volatility. Unlike the classic Black Scholes option pricing formula, it assumes that the underlying variance of an asset's return is not constant. That is, the variance of the underlying asset return is treated as a latent random variable. This deals with some of the empirical short comings of the BS model such as the volatility smile and skew in the realised variance in financial assets. 

SV models are typically expressed as non linear Gaussian state space models. This can make it difficult to estimate using classical methods. The likelihood is unavailable in closed form and there are at least as many variables as data points. There are however, a variety of Frequentist and Bayesian strategies for estimating SV models. Frequentist approaches include quasi likelihood estimation and GMM which rely on asymptotic sampling distributions. Bayesian approaches rely on computational Markov Chain Monte Carlo techniques to sample from the target joint posterior of these high dimensional state space models. 

This research will focus on Bayesian estimation strategies for Stochastic Volatility models. Particular attention will be given to the computational tools and approaches used to sample from high dimensional posterior distributions. Early approaches for estimating these models relied on classic Gibbs and Metropolis Hastings algorithms to apply the MCMC routines. Since then, there have been many developments in the availability of new kinds of MCMC samplers. 

Hamiltonian Monte Carlo is a . It has been popularised through its implementation in a variety of open source programming languages. It presents a new way to sample from increasingly complicated generative models . 

However, as the developments of these tools enable the estimation of more complicated models (with relative ease and accessibility through the development of open source software), so do the risk of mistakes and the need for procedures diagnose problems or mistakes when implementing these methods. How do we know that these algorithms are doing what we expect them to be doing, and how can we effectively differentiate the strengths and weaknesses of different tools.

How do we validate the computation and implementation of our sampling strategies and algorithms in increasingly complex models? And how do these form part of the computational modelling workflow?    -->

<!-- ## HMC
- There have been many developemnts over the past few decades on estimating Bayesian models through Markov Chain Monte Carlo methods. 

The original BUGs software implemented Gibbs and Metropolis Hastings MCMC algorithms for estimating this model. 

In particular, the implementation of Hamiltonian Monte Carlo, a variant of the Metropolis Hastings algorithm, represents a recent advancement MCMC. 

- The development of HMC is another advancement in estimating complicated, high dimensional models. 
- Development of diagnostics for different types of HMC and tools for evaluating the convergence and efficiency of the MCMC sampler.  

- SV models are a primary candidate for using MCMC methods? Difficult to 

## SBC -->

## Research Goal
The objective of this research is to validate and compare the comutational methods used to estimate Bayesian Stochastic Volatiity models. Specifically, Simulation Based Calibration will be used to identify biases and errors arising from the results of Markov Chain Monte Carlo (MCMC) algorithms. The source of any miscalibration include, but are not limited to, estimation strategies, choice of sampler, model specifications and coding mistakes. This study will compare the estimation strategies detailed in the stochastic volatility literature with Hamiltonian Monte Carlo for estimating these class of models. Results and diagnostics from these simulations will help identify strengths and limitations that arise from these approaches.

<!-- and provide tools for evaluating other types models and algorithms.  -->

<!-- The objective of this research is to evaluate the performance of MCMC algorithms for estimating SV models through a simulation study. Simulations are useful since there is control over the data generating process. This will help us understand the behaviour of MCMC and evaluate its performance against known parameters. Particular attention will be given to the calibration of the MCMC algorithms in the stochastic volatility context. Further diagnostics to evaluate performance will be explored to determine the efficiency of the MCMC sampler. 

The first step is to understand what "performance" of MCMC algorithms means and what exactly we are measuring. At a high level, the objective of MCMC is to sample from the target posterior distribution and to provide reliable inference.  Convergence to the target posterior can be measured through efficiency measures such as rhat and effective sample size. 

- Explcitly outline what is compared. KSC and HMC algorithms and estimation strategies.  -->

<!-- 
Frequentist methods 

- Variety of estimation strategies 

- There are a variety of ways of estimating this model using a Bayesian frameworks. 

Over the past few decades there have been many developments in computing hardware -->
<!-- 
RESEARCH GOAL: To compare the performance of different MCMC algorithms and estimation strategies when fitting stochastic volatility models. The study will use a discrete formulation is described  -->

# Background and Literature Review

Kim, Sherpherd and Chib (1998) estimate the discrete time stochastic volatility model by proposing a simulation strategy using Bayesian methods. Specifically, they propose a method of sampling using an offset mixture normal approximation with a reweighting procedure to sample from the posterior of the stochastic volatility model parameters. By linearing the model and using a mixture of Gaussian's, they were able to apply a Kalman Filter to estimate the posterior density over the latent volatilities and static parameters. The use of simulation and sampling are used as part of model diagnostics and evaluation. This is compared with other estimation strategies and volatility models such as autogregressive conditional heteroskedasticity (ARCH). Their specificaiton of the stochastic volatility model and estimation approaches provide the context for comparing the performance of different MCMC algorithms. 

The simulations run by Kim, Sherpherd and Chib rely on sampling directly from conjugate priors and use of classic MCMC algorithms, Gibbs and Metropolis Hastings. Since the paper was written, new MCMC algorithms have been developed and enabled the estimation of richer and more complicated models. Specifically, Hamiltonian Monte Carlo is an a MCMC algorithm which has been become widely available for efficiently sampling from sophisticated models. Hamiltonian Monte Carlo, originally called Hybrid Monte Carlo was developed in the physics literature (Duane et al., 1987) before being applied in the statistics literature by Radford Neal through his works in Bayesean Neural Networks (Nael, 1995) and statistical computing (Neal 2011). The algorithm has since become widely available through open source developement projects such as Stan (Stan Development Team, 2023) and PyMC (2023). 

The key innovation of Hamiltonian Monte Carlo is using the gradients of the target posterior distribution to generate an efficient path for the sampler to explore. Unlike Random Walk Metropolis Hastings, it takes advantage of the geometry of the posterior to determine its next step. A comprehensive explanation of the sampler is beyond the scope of this research and can be found in the above references. 

New developments in MCMC algorithms and improved computing resources have enabled estimation of richer and more complicated models. However, as the development of tools to enable us to fit more complicated models, so does the need to validate the output of these tools. Cook, Gelman and Rubin (2006) introduce simulation techniques to evaluate the "correctness" of the software used to sample Bayesian models. Their contribution identified that cumulative density quantiles from the posterior samples will be uniformly distributed. Talts et al. build upon this work by developing Simulation Based Calibration to provide more robust validation of output from a MCMC sampler through the use of rank statistics. 

 <!-- through the use of the CDF quantiles approximated from the posterior distribution. -->

<!-- , through open source programming languages such as Stan and PyMC, have become 

As new and complicated 


There have been many developments in MCMC algorithms since the introduction of classical methods such as Gibbs and Metropolis Hastings. 

Hamiltoninn Monte Carlo (algorithm introduced when, widely available since 2010...?) is a relatively new im.


- Since then, there have been many developments in MCMC algorithms. In particular, HMC provides a flexible alternative to fitting and sampling from complicated high dimensional Bayesian models.
- It's key innovation is the use of gradients - enabling the flexible specification of any likelihood function. 
- Constraints- can only sample from continuous 
- HMC also provides new diagnostics for evaluating the effectiveness of the sampling procedure and how well the sampler is targeting the joint dist. 

- How do we compare models? SBC. ESS in the tails, rhats. 

- Given this context, my research looks to compare the efficacy of KSCs proposed MCMC sampling strategy with Hamiltonina Monte Carlo (NUTs).  -->
 



# 3) Methodology
The aim of this research is to use Simulation Based Calibration (SBC) to validate the inference of posterior samples generated by different MCMC algorithms in the context of Stochastic Volatility models. This will help identify any bias in computation and inconsistencies in model implementation and estimation strategies. Comparison of the SBC results between different computational approaches may help identify any strengths or shortcomings as well as any errors in model specification. 

## 3.1) Stochastic Volatility Model
The univariate stochastic volatility model described by Kim, Shepherd and Chib (1998), models the variance as a random variable following some latent stochastic process. $y_t$ is the mean corrected returns of some asset for equally spaced intervals t. $\beta$ is a constant scaling factor which is also defined as $exp(\mu / 2)$ representing instantaneous volatility. $h_t$ is log volatility, where $h_1$ is a draw from a stationary distribution and the state equation $h_{t+1}$ follows a stationary process governed by the autoregressive parameter $\phi$ such that $|\phi|<1$. This autoregressive parameter represents the persistence or "stickiness" of log volatility and the dispersion parameter $\sigma_{\eta}$ is its variance. $\epsilon_t$ and $\eta_t$ are standard normal white noise shocks. 

$$
\begin{aligned}
y_t =& \space \beta exp(h_t/2) \epsilon_t \\
h_{t+1} =& \space \mu +\phi(h_t - \mu) + \sigma_{\eta} \eta_t  \\
h_1 \sim& \space normal\left(\mu, \frac{\sigma_{\eta}^2}{1-\phi^2}\right) \\
\end{aligned}
$$


$$
\begin{aligned}
\epsilon_t \sim& \space normal(0,1) \\
\delta_t \sim& \space normal(0,1)
\end{aligned}
$$

Setting $\beta=1$, the model can be expressed more succinctly as:

$$
\begin{aligned}
y_t \sim& \space normal(0, exp(h_t/2)) \\ 
h_1 \sim& \space normal \left(\mu, \frac{\sigma_{\eta}^2}{1-\phi^2}\right) \\
h_{t+1} \sim& \space normal(\mu +\phi(h_t - \mu) , \sigma_{\eta}^2), \space\space t\neq 1\\ 
\end{aligned}
$$

Priors for the static parameters are defined below with $\mu$ and $\sigma^2$ being conjugate priors:

$$
\begin{aligned}
\mu \sim& \space normal(0, 10^2) \\
\sigma_{\eta}^2 \sim& \space IG(5/2, (0.01\times 5) / 2) \\
\phi^{\ast} \sim& \space beta(20, 1.5) \\
\phi &=  2\phi^{\ast} - 1
\end{aligned}
$$

The prior on $\phi$ is a "stretched" beta distribution. This is a beta distribution (as defined on the parameter $\phi^*$) which has been transformed to have support (-1, 1).

## 3.2) Estimation Strategy

### Gaussian Mixture Approximation
Kim Shepherd and Chib estimate the stochastic volatility model using a Kalman Filter and smoother[^1] (de Jong and Shephard, 1995) to compute the posterior distribution over the latent states. This requires the state space model to be linear and conditionally Gaussian. 

[^1]: In this research the exact software to apply the simulation smoother is unavailable, so a more recent simulation smoother is used which is based on the software written by the same author. 

Since the model is not linear, a transformation is applied by squaring and taking the log of $y_t$.

$$
\begin{aligned}
y_t^{*} &= log(y_t^2) \\ 
&= log((\epsilon_t exp(h_t/2))^2) \\
&=  log(exp(h_t)) + log(\epsilon_t^2) \\
&= h_t + log(\epsilon_t^2)  \\
&= h_t + z_t \\
\end{aligned}
$$

Where $z_t = log(\epsilon_t^2)$ follows a log chi-squared distribution with mean -1.2704 and varaince 4.93. However, it is not simple to sample from this parameterisation of the model. Kim, Sherpherd and Chib use a mixture of Gaussians to **approximate** the first 4 moments of the log chi squared distribution. This is defined by:

$$
\begin{aligned}
f(z_t) = \sum_{i=1}^{K} q_if_N(z_i|m_i-1.2704, \nu_i^2)
\end{aligned}
$$

Where K is the mixture of normal densities $f_N$, component probabilities $q_i$, mean $m_i-1.2704$ and variance $\nu_i^2$. These parameters were seleted using moment matching where they found 7 normal densities with varying mean and variance parameters best approximated the log chi squared moments. These parameters and weights can be found in Appendix A.

The model can be sampled via the simulation smoother since the model is now linear and conditionally gaussian. The static parameters $\mu$ and $\sigma^2$ are sampled directly from their conjugate posterior distributions where as $\phi$ is sampled via a metropolis hastings accept/reject procedure. The details can be be around in Appendix B. 

### Hamiltonian Monte Carlo (No-U-Turn Sampler)
The Stan programming language's implementation of Hamiltonian Monte Carlo will be used for this study. Stan's default algorithm, the No-U-Turn Sampler (Hoffman & Gelman 2014), allows for direct sampling of the spcified stochastic volatility model. Hamiltonian Monte Carlo allows for sampling of the generative model and can flexibly handle complicated likelihood functions. This approach will use the same priors are specified in the Gaussian mixture approximation. However, Hamiltonian does not sample directly from the analytical form of conjugate or conditionally conjugate distribution, so different priors can be chosen if necessary. 

## 3.3 Simulation Based Calibration (SBC)
<!-- SBC validates posterior samples and inferences generated by MCMC algorithms. It identifies inconsistencies and bias in computation and estimation of a generative model. This procedure  -->

SBC is conducted by comparing the distribution of rank statistics to the discrete uniform distribution which arises when an algorithm is correctly calibrated. The procedure starts by taking draws from the prior distribution and creating datasets implied by each draw. Rank statistics are then calculated on the posterior samples estimated from the simulated data. Let $\theta$ be a parameter and $y$ represent the dataset. Start with draw a sample from the prior distribution:
$$
\begin{aligned}
\theta^{sim} \sim \pi(\theta)
\end{aligned}
$$

Generate a dataset given by the prior draws.

$$
\begin{aligned}
y^{sim} \sim \pi (y|\theta^{sim})
\end{aligned}
$$

Then take draws from the posterior distribution generated by a MCMC algorithm or estimation strategy (Hamiltonian Monte Carlo or Gaussian apprimation in our case).

$$
\begin{aligned}
\{\theta_1,\dots , \theta_{L}\} \sim \pi (\theta | y^{sim})
\end{aligned}
$$

A key result from this procedure is that the posterior sample $\{\theta_1,\dots , \theta_{L}\}$ will share the same distribution as the prior samples $\theta^{sim}$. This is implied by the following expression:

$$
\begin{aligned}
\pi(\theta) &= \int \pi(\theta|y^{sim}) \pi(y^{sim}|\theta^{sim}) \pi(\theta^{sim})dy^{sim} d\theta^{sim} \\
&= \int \pi(\theta|y^{sim}) \pi(y^{sim},\theta^{sim}) dy^{sim} d\theta^{sim}
\end{aligned}
$$

That is, the posterior averaged over the joint distribution follows the same distribution as the prior. The procedure of generating posterior samples implicitly performs this integral since the expression on the right of the integral is proportional to the prior density. Therefore, any deviation of the posterior samples from the prior distribution suggests an error - either in computation, code or overall analysis. 

<!-- The simulation if done correctly should produce samples from the prior distribution.  -->

Since the distribution of the posterior samples follows the prior distribution, the rank statistic for a given parameter and simultion follows a discrete uniform distribution[^2].

[^2]: Proof of this result in Talts et al 2018.

$$
\begin{aligned}
r = rank(\{\theta_1,\dots , \theta_{L}\}, \theta^{sim}) = \sum_{l=1}^{L}1[\theta_{l} < \theta^{sim}]
\end{aligned}
$$

This completes one iteration of SBC. To complete the algorithm, multiple iterations are run and the rank statistics are calculated for each parameter. The resulting rank statistics are compared to the discrete uniform distribution to determine if any problematic features or errors exist.

If the computation is well calibrated and the samples follow a discrete uniform distribution, then the posterior (credible) intervals will have sufficient coverage. That is, for any percentage interval selected (for example 90%) then there is 90\% chance that any $\theta^{sim}$ falls within this interval. In other words, a Bayesian analysis and computation is well calibrated if 90\% of constructed intervals contain the "true" parameter 90\% of the time. 

<!-- ## Performance diagnostics

The goal of this simulation is to determine the "calibration" of MCMC when estimating SV models. 

ADEMP:
- Aims
- Data generating mechanism
    + Write out mathematical form of the model here. Discrete time. 
- Estimand /target of analysis (maybe after explaining SBC?)
- Methods
    + SBC. Evaluating "calibration" of MCMC. What does calibration mean?
- Performance measures
    + Rhats, ESS, histogram


- Convergence diagnostic onto target joint posterior distribution? rhats/ess. This assess "efficiency" of MCMC.
- Tail ESS calculates ESS in the tail quantiles. Such  -->

# Results
SBC for Hamiltonian Monte Carlo and the Gaussian approxmiation are performed with simulated dataset sizes of 1000 simulation interations, 1000 observations, and post warmup/burnin samples of 999 (which gives 1000 possible rank statistics). The histogram is drawn with 20 bins and 50 observations in each bin which is the expected count for a discrete uniform distribution. This algorithm is summarised below: 

| **1) for n in 1000 iterations:**
|   2) Draw from prior: $\theta^{sim}\sim\pi (\theta)$
|   3) Simulate dataset with 1000 observations: $y^{sim} \sim p(y|\theta^{sim})$
|   4) Draw 999 posterior samples (post warmup) $\{\theta_1,\dots , \theta_{L}\} \sim p(\theta | y^{sim})$
|   5) Compute rank statistics $r = rank(\{\theta_1,\dots , \theta_{L}\}, \theta^{sim})$

Figure 1 shows the the distribution of rank statistics for Hamiltonian Monte Carlo, with the horizontal black line at 50 representing the discrete uniform distribution. The preliminary figures focus on the static parameters and arbitrarily chosen states (since there is one state parameter per data observation). Phi and sigma_sqd look relatively uniform. However mu and h.995 have some lumpiness which may suggest a lack of calibration. 

![Distribution of parameter ranks for HMC algorithm (1000 iterations)](../../simulation_output/sbc_ncp_ksc_priors_0.999_adapt_delta_premade_datasets_r7_1000_iterations/static_state_hist.png){width=75%}

One of the drackbacks of SBC is that any deviation from uniform from a calibrated analysis maybe due to finite samples. Figure 2 shows more consistent uniform bahviour from all parameters after increasing the number of iterations from 1000 to 5000. This suggests that Hamiltonian Monte Carlo and overall analysis is well calibrated.

![Distribution of parameter ranks for HMC algorithm (5000 iterations)](../../simulation_output/sbc_ncp_ksc_priors_0.999_adapt_delta_premade_datasets_r6_5000_iterations/static_state_hist.png){width=75%}

Figure 3 shows results for the Gaussian approximation. The distribution of the rank statistics deviate heavily from the expected discrete uniform distribution, with various peaks at each end of the histogram as well as peaks in the middle. This lack of calibration is expected. The Gaussian approximiation only approximates the log chi squared distribution, where as Hamiltonian Monte Carlo samples directly from the same likelihood as the data generating process. 

![Distribution of parameter ranks for KSC sampling strategy (1000 iterations)](../../simulation_output/sbc_cp_ksc_model_cp_dgf_r1/static_state_hist.png){width=75%}

An alternative to checking for uniformity of all the parameters is to calculate the chi squared statistics for the counts in each bin. Let $b_j$ be the number of counts and $e_j$ the expected count in bin $j$. Then the chi squared statistic is given by:

$$
\begin{aligned}
\chi^2 = \sum_{j=1}^J \frac{(b_{j} - e_{j})^2}{e_j}
\end{aligned}
$$

These chi squared statistics can be considered independent draws from a chi squared distribution with 19 degrees of freedom (since there are 20 bins). Visualising this should give a chi squared distribution (if performing a hypothesis test, this would be the sampling distribution under a null of uniformity). 

Figure 4 are the chi squared statistic histograms results of Hamiltonian Monte Carlo and Gaussian approximation respectively. The vertical black line marks the 95th quantile which represents the critical value for hypothesis testing. The HMC chi squared statistics look like they are sampled from the correct distribution, with 6.2\% of the samples greater than the 95\% critical value (doing this calculation for 5000 iterations leads to 4.8\% of samples in the critical area). Figure 5 shows the majority of chi squared statistics for Gaussian approximation within the critical area, suggesting the estimation strategy is not well calibrated. 

![Chi squared statistics for HMC](../../simulation_output/sbc_ncp_ksc_priors_0.999_adapt_delta_premade_datasets_r7_1000_iterations/chi_sq_hist.png){width=70%}

![Chi squared statistics for KSC](../../simulation_output/sbc_cp_ksc_model_cp_dgf_r1/chi_sq_hist.png){width=70%}

# Conclusion and next steps
There are two key extensions to the simulation results worth exploring.

**1) Metropolis Hastings reweighting for KSC model**

Kim, Sherpherd and Chib apply a Metropolis Hastings reweighting to the posterior samples to correct for the approximation of the error distribution. According to the authors, the correction ensures that samples are from the exact posterior density. The next step is to perform this correction and evaluate the SBC results. I'd expect the Gaussian mixture approximation diagnostics to improve after this correction.

**2) Centered and non centered parameterisation**

The parameterisation of a model can affect the performance of a sampler. This can cause significant problems in getting unbiased MCMC samples for complex models. An example of this is Neal's funnel (Neal 2003) which arises in hierarchical models which causes performance issues with the Hamiltonian Monte Carlo sampler. Rewriting the model with non centered parameterisation significantly improves the performance of MCMC. Another consideration for this research is to consider both centered and non centered parametersations of the stochastic volatility model to see if there are any improvements to the simulation diagnostics.

The models and parametiersations for this research are summarised in the below table:

![Model matrix](model_table.png)

## Plan
Week 7: Reflect and integrate feedback from presentation into plan for the rest of the semester

Week 8: Finish off any simulation or modelling not yet complete (listed in above matrix)

Week 9: Write up any other results and have a first draft ready for feedback

Week 10-11: Action any feedback, prepare for final submission and presentation

Week 12: Submit

# References

Abril-Pla O, Andreani V, Carroll C, Dong L, Fonnesbeck CJ, Kochurov M, Kumar R, Lao J, Luhmann CC, Martin OA, Osthege M, Vieira R, Wiecki T, Zinkov R. (2023) PyMC: a modern, and comprehensive probabilistic programming framework in Python.

Duane, Simon; Kennedy, Anthony D.; Pendleton, Brian J.; Roweth, Duncan (1987). "Hybrid Monte Carlo". Physics Letters B. 195 (2): 216–222. 

Hoffman, M. D., & Gelman, A. (2014). The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo. J. Mach. Learn. Res., 15(1), 1593-1623.

Kim, Sangjoon, Neil Shephard, and Siddhartha Chib. 1998. “Stochastic Volatility: Likelihood Inference and Comparison with ARCH Models.” Review of Economic Studies 65: 361–93. 

Neal, R.M. (1995) Bayesian Learning for Neural Networks. Ph.D. Thesis, Graduate Department of Computer Science, University of Toronto, Toronto. 

Neal, R. M. (2003). Slice Sampling. The Annals of Statistics, 31(3), 705–741. http://www.jstor.org/stable/3448413

Neal, R.M. (2011) MCMC Using Hamiltonian Dynamics. In Handbook of Markov Chain Mone Carlo, CRC Press, New York

Stan Development Team. 2023. Stan Modeling Language Users Guide and Reference Manual, 2.32. https://mc-stan.org

Talts, S., Betancourt, M., Simpson, D., Vehtari, A., & Gelman, A. (2018). Validating Bayesian inference algorithms with simulation-based calibration. arXiv preprint arXiv:1804.06788.

# Appendix A: Mixture Gaussian weights

# Appendix B: Conjugate posterior distributions

